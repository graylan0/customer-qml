{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOQqCUvId0nO73GzkwG4KdB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/graylan0/customer-qml/blob/main/GPT4_Vision_Audio_Aesthetics.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MwQvgM00dp03"
      },
      "outputs": [],
      "source": [
        "!pip install git+https://github.com/suno-ai/bark.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai\n",
        "!pip install librosa"
      ],
      "metadata": {
        "id": "KPSz_mHadqfy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "import librosa\n",
        "import librosa.display\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import base64\n",
        "import requests\n",
        "from bark import SAMPLE_RATE, generate_audio, preload_models\n",
        "from scipy.io.wavfile import write as write_wav\n",
        "import uuid\n",
        "import os\n",
        "import concurrent.futures\n",
        "\n",
        "\n",
        "preload_models()\n",
        "userdata.get('OPENAI_API_KEY')\n",
        "\n",
        "\n",
        "def generate_audio_for_sentence(sentence):\n",
        "    try:\n",
        "        return generate_audio(sentence)\n",
        "    except Exception as e:\n",
        "        print(\"Error in generating audio for sentence: {}\".format(e))\n",
        "        return None\n",
        "\n",
        "def generate_response(song_elements, num_threads=4):\n",
        "    pieces = []\n",
        "    with concurrent.futures.ThreadPoolExecutor(max_workers=num_threads) as executor:\n",
        "        future_to_element = {executor.submit(generate_audio_for_sentence, element.get('lyrics', element.get('music'))): element for element in song_elements if 'lyrics' in element or 'music' in element}\n",
        "        for future in concurrent.futures.as_completed(future_to_element):\n",
        "            try:\n",
        "                audio_array = future.result()\n",
        "                if audio_array is not None:\n",
        "                    pieces.append(audio_array)\n",
        "                    element = future_to_element[future]\n",
        "                    if 'pause' in element:\n",
        "                        silence = np.zeros(int(element['pause'] * SAMPLE_RATE))\n",
        "                        pieces.append(silence)\n",
        "            except Exception as e:\n",
        "                print(\"Error processing element: {}\".format(e))\n",
        "\n",
        "    if pieces:\n",
        "        audio = np.concatenate(pieces)\n",
        "        file_name = str(uuid.uuid4()) + \".wav\"\n",
        "        try:\n",
        "            write_wav(file_name, SAMPLE_RATE, audio.astype(np.int16))\n",
        "            return file_name\n",
        "        except Exception as e:\n",
        "            print(\"Error writing audio file: {}\".format(e))\n",
        "            return None\n",
        "    else:\n",
        "        return None\n",
        "\n",
        "def create_spectrogram(audio_path, save_path):\n",
        "    try:\n",
        "        y, sr = librosa.load(audio_path)\n",
        "        plt.figure(figsize=(10, 4))\n",
        "        S = librosa.feature.melspectrogram(y=y, sr=sr)\n",
        "        librosa.display.specshow(librosa.power_to_db(S, ref=np.max), sr=sr, x_axis='time', y_axis='mel')\n",
        "        plt.colorbar(format='%+2.0f dB')\n",
        "        plt.title('Mel-frequency spectrogram')\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(save_path)\n",
        "        plt.close()\n",
        "    except Exception as e:\n",
        "        print(\"Error creating spectrogram: {}\".format(e))\n",
        "\n",
        "def encode_image(image_path):\n",
        "    try:\n",
        "        with open(image_path, \"rb\") as image_file:\n",
        "            return base64.b64encode(image_file.read()).decode('utf-8')\n",
        "    except Exception as e:\n",
        "        print(\"Error encoding image: {}\".format(e))\n",
        "        return None\n",
        "\n",
        "def gpt4_vision_agent_prompt(image_path):\n",
        "    base64_image = encode_image(image_path)\n",
        "    if not base64_image:\n",
        "        return None\n",
        "\n",
        "    headers = {\n",
        "        \"Content-Type\": \"application/json\",\n",
        "        \"Authorization\": \"Bearer {}\".format(os.getenv('OPENAI_API_KEY'))\n",
        "    }\n",
        "    payload = {\n",
        "        \"model\": \"gpt-4-vision-preview\",\n",
        "        \"messages\": [\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": [\n",
        "                    {\"type\": \"text\", \"text\": \"Analyze the aesthetics of this spectrogram. Describe its visual qualities, patterns, and any notable features.\"},\n",
        "                    {\"type\": \"image_url\", \"image_url\": {\"url\": \"data:image/jpeg;base64,{}\".format(base64_image)}}\n",
        "                ]\n",
        "            }\n",
        "        ],\n",
        "        \"max_tokens\": 300\n",
        "    }\n",
        "    try:\n",
        "        response = requests.post(\"https://api.openai.com/v1/chat/completions\", headers=headers, json=payload)\n",
        "        response.raise_for_status()\n",
        "        return response.json()\n",
        "    except Exception as e:\n",
        "        print(\"Error in GPT-4 Vision Agent request: {}\".format(e))\n",
        "        return None\n",
        "\n",
        "def process_audio_and_analyze_aesthetics(song_elements):\n",
        "    audio_file = generate_response(song_elements)\n",
        "    if audio_file:\n",
        "        spectrogram_path = 'spectrogram.jpg'\n",
        "        create_spectrogram(audio_file, spectrogram_path)\n",
        "        return gpt4_vision_agent_prompt(spectrogram_path)\n",
        "    else:\n",
        "        return None\n",
        "\n",
        "def gpt4_audio_influencer_mixer_engineer_prompt(analysis_result):\n",
        "    if not analysis_result:\n",
        "        return None\n",
        "    try:\n",
        "        visual_descriptions = analysis_result['choices'][0]['message']['content']\n",
        "        prompt = \"Based on the following spectrogram analysis: {}, suggest modifications to the music elements to enhance its aesthetic appeal and emotional impact.\".format(visual_descriptions)\n",
        "        modified_elements = interact_with_gpt35(prompt)\n",
        "        return modified_elements\n",
        "    except Exception as e:\n",
        "        print(\"Error in GPT-4 audio influencer mixer engineer prompt: {}\".format(e))\n",
        "        return None\n",
        "\n",
        "def super_sim_advance_ai(number_of_iterations=5):\n",
        "    song_elements = []\n",
        "    for _ in range(number_of_iterations):\n",
        "        analysis_result = process_audio_and_analyze_aesthetics(song_elements)\n",
        "        if analysis_result:\n",
        "            song_elements = adjust_song_elements(song_elements, analysis_result)\n",
        "\n",
        "super_sim_advance_ai()\n"
      ],
      "metadata": {
        "id": "PMKLo-Gvdqii"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}